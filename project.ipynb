{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANLP Oct 2024 Project - Jason Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do write food reviews in my leisure time and have created a [food telegram bot](https://t.me/jasonthefoodie_bot) for my users to retrieve my reviews. Currently, I am using GPT-4o-mini to auto assign a score to these reviews but they are not too accurate.\n",
    "\n",
    "The scope of my project will be to fine-tune a small LM to analyse the sentiments of given reviews and tag them a score between 1 to 5. The fine-tuned model should hopefully do better than the GPT-4 and the non fine-tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries and create train/test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have scraped my food reviews from Burpple: https://www.burpple.com/@jasoneatfoodd/timeline and there are about 1000 reviews after removal of duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn torch transformers accelerate ipywidgets unsloth bitsandbytes langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>num_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recently tried @toriyamasg 's yakitori and I m...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finally tried @doqoosg 's famous mochi waffles...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Got myself a bowl of dry Ban Mian with meatbal...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Korean BBQ restaurants are in abundance here i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you have a spicy appetite, @xiaolongkansg w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  num_stars\n",
       "0  Recently tried @toriyamasg 's yakitori and I m...          4\n",
       "1  Finally tried @doqoosg 's famous mochi waffles...          4\n",
       "2  Got myself a bowl of dry Ban Mian with meatbal...          5\n",
       "3  Korean BBQ restaurants are in abundance here i...          5\n",
       "4  If you have a spicy appetite, @xiaolongkansg w...          3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('reviews_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test on baseline model and GPT-4o-mini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first evaluate the accuracy of GPT-4o-mini model and the baseline llama-3.2-1B-instruct model in rating the reviews correctly, against the groundtruth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system prompt and instruction to instruct the LLM\n",
    "system_prompt = \"You are a food critic. You will be provided written food reviews to rate.\"\n",
    "instruction = \"\"\"\n",
    "Rate the food review on a scale between 1 to 5.\n",
    "Only return the number of the rating.\n",
    "\n",
    "Rating:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the openai LLM\n",
    "llm = AzureChatOpenAI(\n",
    "                azure_endpoint=\"OPENAI_ENDPOINT\",\n",
    "                openai_api_type=\"azure\",\n",
    "                openai_api_key=\"OPENAI_KEY\",\n",
    "                azure_deployment=\"gpt-4o-mini\",\n",
    "                openai_api_version=\"2024-08-01-preview\"\n",
    "            )\n",
    "\n",
    "# function to format the LLM output\n",
    "def openai_generate(prompt):\n",
    "    return llm(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the llama LLM\n",
    "model_id = \"./Llama-3.2-1B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to format the LLM output\n",
    "def llama_generate(pipe, input_text, system_prompt):\n",
    "    messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": input_text}\n",
    "            ]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    output = pipe(\n",
    "        prompt,\n",
    "        max_length=2048,\n",
    "        return_full_text=False,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    text = output[0][\"generated_text\"]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rate reviews using an LLM and calculate accuracy against ground truth ratings.\n",
    "def rate_reviews(df, llm_model, system_prompt, instruction, llm_type, pipe=None):\n",
    "    \"\"\"\n",
    "    Function to rate reviews using an LLM and calculate accuracy against ground truth ratings.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataframe containing 'reviews' and 'groundtruth' columns.\n",
    "    llm_model: The large language model capable of generating ratings from reviews.\n",
    "    system_prompt (str): The system prompt that instructs the LLM on how to generate ratings.\n",
    "    \n",
    "    Returns:\n",
    "    accuracy (float): The accuracy score comparing LLM ratings to groundtruth ratings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a list to hold LLM-generated ratings\n",
    "    llm_ratings = []\n",
    "    \n",
    "    # Iterate over each review in the dataframe\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        while True:\n",
    "            try:\n",
    "                # Extract the review\n",
    "                review = row['review']\n",
    "                \n",
    "                if llm_type == 'openai':\n",
    "\n",
    "                    # Create a prompt to send to the LLM\n",
    "                    prompt = f\"{system_prompt}\\nReview: {review}\\n{instruction}\"\n",
    "                \n",
    "                    # Send the prompt to the LLM to generate a rating (assuming LLM returns a rating as integer)\n",
    "                    llm_generated_rating = llm_model(prompt)\n",
    "\n",
    "                elif llm_type == 'llama':\n",
    "                    llm_generated_rating = llm_model(pipe, review + \"\\n\" + instruction, system_prompt)\n",
    "\n",
    "                llm_generated_rating = int(llm_generated_rating)\n",
    "                break\n",
    "            \n",
    "            except ValueError:\n",
    "                continue\n",
    "            \n",
    "        # Append the generated rating to the list\n",
    "        llm_ratings.append(llm_generated_rating)\n",
    "    \n",
    "    # Add the LLM-generated ratings to the dataframe\n",
    "    df['llm_ratings'] = llm_ratings\n",
    "    \n",
    "    # Calculate accuracy using the ground truth and the generated ratings\n",
    "    accuracy = accuracy_score(df['num_stars'], df['llm_ratings'])\n",
    "    \n",
    "    return df, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [17:34<00:00,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7575757575757576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy score for GPT4o-mini\n",
    "openai_df, openai_acc = rate_reviews(test, openai_generate, system_prompt, instruction, 'openai')\n",
    "print(openai_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [01:14<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31313131313131315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy score for llama\n",
    "llama_df, llama_acc = rate_reviews(test, llama_generate, system_prompt, instruction, 'llama', pipe)\n",
    "print(llama_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, it is obvious that the 1B model performs much worse than GPT-4o-mini. Let's see if we can close the gap by fine-tuning it with some of the review data and their respective groundtruth ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Finetune Llama3.2 using qLORA via Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.9.post4: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090 Laptop GPU. Max memory: 15.6 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "# initialise quantised llama 3 model\n",
    "max_seq_length = 2048\n",
    "ft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"./Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise quantised llama 3 model\n",
    "ft_model = FastLanguageModel.get_peft_model(\n",
    "    ft_model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"], \n",
    "    use_rslora=True,\n",
    "    use_gradient_checkpointing=\"unsloth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup and format training datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{context}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{answer}<|eot_id|>\"\"\"\n",
    "\n",
    "def format_dataset(df, system_prompt):\n",
    "    review_ls = df['review'].tolist()\n",
    "    rating_ls = df['num_stars'].tolist()\n",
    "\n",
    "    # Create a list to store the formatted text\n",
    "    formatted_data = []\n",
    "\n",
    "    # Iterate over the reviews and ratings\n",
    "    for review, rating in zip(review_ls, rating_ls):\n",
    "        # Format the template with the current review and rating\n",
    "        formatted_text = TEMPLATE.format(\n",
    "            context=system_prompt,\n",
    "            question=review,\n",
    "            answer=str(rating)  # Ensure rating is converted to string\n",
    "        )\n",
    "        # Append the formatted text to the list\n",
    "        formatted_data.append({\"text\": formatted_text})\n",
    "\n",
    "    # Convert the list of dictionaries into a Dataset object\n",
    "    dataset = Dataset.from_list(formatted_data)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "ft_train = format_dataset(train, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 73 | Num Epochs = 15\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 2\n",
      "\\        /    Total batch size = 16 | Total steps = 75\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378a7f08eb534f11b8a05ae706918a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5708, 'grad_norm': 5.317651748657227, 'learning_rate': 9e-05, 'epoch': 0.2}\n",
      "{'loss': 3.559, 'grad_norm': 5.036423206329346, 'learning_rate': 0.00018, 'epoch': 0.4}\n",
      "{'loss': 3.3079, 'grad_norm': 3.9521358013153076, 'learning_rate': 0.00027, 'epoch': 0.6}\n",
      "{'loss': 3.0138, 'grad_norm': 2.1832804679870605, 'learning_rate': 0.00036, 'epoch': 0.8}\n",
      "{'loss': 2.8699, 'grad_norm': 2.3651890754699707, 'learning_rate': 0.00045, 'epoch': 1.0}\n",
      "{'loss': 2.758, 'grad_norm': 1.5491721630096436, 'learning_rate': 0.00054, 'epoch': 1.2}\n",
      "{'loss': 2.6457, 'grad_norm': 1.6231796741485596, 'learning_rate': 0.0006299999999999999, 'epoch': 1.4}\n",
      "{'loss': 2.6013, 'grad_norm': 1.5870009660720825, 'learning_rate': 0.00072, 'epoch': 1.6}\n",
      "{'loss': 2.6139, 'grad_norm': 1.6099863052368164, 'learning_rate': 0.00081, 'epoch': 1.8}\n",
      "{'loss': 2.5652, 'grad_norm': 1.6665542125701904, 'learning_rate': 0.0009, 'epoch': 2.0}\n",
      "{'loss': 2.4407, 'grad_norm': 1.3268182277679443, 'learning_rate': 0.0008861538461538462, 'epoch': 2.2}\n",
      "{'loss': 2.3631, 'grad_norm': 0.8479907512664795, 'learning_rate': 0.0008723076923076923, 'epoch': 2.4}\n",
      "{'loss': 2.2794, 'grad_norm': 0.7750355005264282, 'learning_rate': 0.0008584615384615385, 'epoch': 2.6}\n",
      "{'loss': 2.262, 'grad_norm': 0.6703326106071472, 'learning_rate': 0.0008446153846153846, 'epoch': 2.8}\n",
      "{'loss': 2.1466, 'grad_norm': 0.841603696346283, 'learning_rate': 0.0008307692307692308, 'epoch': 3.0}\n",
      "{'loss': 2.1252, 'grad_norm': 0.6667285561561584, 'learning_rate': 0.0008169230769230768, 'epoch': 3.2}\n",
      "{'loss': 2.1009, 'grad_norm': 0.7863674163818359, 'learning_rate': 0.0008030769230769231, 'epoch': 3.4}\n",
      "{'loss': 2.0623, 'grad_norm': 1.0247174501419067, 'learning_rate': 0.0007892307692307692, 'epoch': 3.6}\n",
      "{'loss': 2.0149, 'grad_norm': 1.6951384544372559, 'learning_rate': 0.0007753846153846154, 'epoch': 3.8}\n",
      "{'loss': 1.973, 'grad_norm': 2.4806275367736816, 'learning_rate': 0.0007615384615384615, 'epoch': 4.0}\n",
      "{'loss': 1.9116, 'grad_norm': 2.008486270904541, 'learning_rate': 0.0007476923076923077, 'epoch': 4.2}\n",
      "{'loss': 1.8705, 'grad_norm': 1.134843349456787, 'learning_rate': 0.0007338461538461538, 'epoch': 4.4}\n",
      "{'loss': 1.761, 'grad_norm': 0.650731086730957, 'learning_rate': 0.00072, 'epoch': 4.6}\n",
      "{'loss': 1.8259, 'grad_norm': 0.8168043494224548, 'learning_rate': 0.0007061538461538462, 'epoch': 4.8}\n",
      "{'loss': 1.8002, 'grad_norm': 1.0837154388427734, 'learning_rate': 0.0006923076923076924, 'epoch': 5.0}\n",
      "{'loss': 1.69, 'grad_norm': 0.8067317008972168, 'learning_rate': 0.0006784615384615385, 'epoch': 5.2}\n",
      "{'loss': 1.6728, 'grad_norm': 1.2622456550598145, 'learning_rate': 0.0006646153846153846, 'epoch': 5.4}\n",
      "{'loss': 1.6472, 'grad_norm': 1.68662428855896, 'learning_rate': 0.0006507692307692307, 'epoch': 5.6}\n",
      "{'loss': 1.6748, 'grad_norm': 1.6214693784713745, 'learning_rate': 0.0006369230769230769, 'epoch': 5.8}\n",
      "{'loss': 1.6636, 'grad_norm': 1.2256914377212524, 'learning_rate': 0.000623076923076923, 'epoch': 6.0}\n",
      "{'loss': 1.4956, 'grad_norm': 0.8053766489028931, 'learning_rate': 0.0006092307692307692, 'epoch': 6.2}\n",
      "{'loss': 1.5168, 'grad_norm': 0.7193288803100586, 'learning_rate': 0.0005953846153846154, 'epoch': 6.4}\n",
      "{'loss': 1.4973, 'grad_norm': 0.724212646484375, 'learning_rate': 0.0005815384615384616, 'epoch': 6.6}\n",
      "{'loss': 1.4723, 'grad_norm': 0.6550503373146057, 'learning_rate': 0.0005676923076923077, 'epoch': 6.8}\n",
      "{'loss': 1.4556, 'grad_norm': 1.1401166915893555, 'learning_rate': 0.0005538461538461539, 'epoch': 7.0}\n",
      "{'loss': 1.3522, 'grad_norm': 1.627687931060791, 'learning_rate': 0.00054, 'epoch': 7.2}\n",
      "{'loss': 1.3417, 'grad_norm': 1.0354321002960205, 'learning_rate': 0.0005261538461538461, 'epoch': 7.4}\n",
      "{'loss': 1.3103, 'grad_norm': 1.114504098892212, 'learning_rate': 0.0005123076923076922, 'epoch': 7.6}\n",
      "{'loss': 1.2571, 'grad_norm': 0.738538920879364, 'learning_rate': 0.0004984615384615384, 'epoch': 7.8}\n",
      "{'loss': 1.2987, 'grad_norm': 2.2863049507141113, 'learning_rate': 0.00048461538461538455, 'epoch': 8.0}\n",
      "{'loss': 1.1993, 'grad_norm': 1.4660606384277344, 'learning_rate': 0.00047076923076923077, 'epoch': 8.2}\n",
      "{'loss': 1.1422, 'grad_norm': 0.8133765459060669, 'learning_rate': 0.0004569230769230769, 'epoch': 8.4}\n",
      "{'loss': 1.1409, 'grad_norm': 1.2852797508239746, 'learning_rate': 0.0004430769230769231, 'epoch': 8.6}\n",
      "{'loss': 1.0765, 'grad_norm': 1.399570345878601, 'learning_rate': 0.00042923076923076926, 'epoch': 8.8}\n",
      "{'loss': 1.0566, 'grad_norm': 1.5554922819137573, 'learning_rate': 0.0004153846153846154, 'epoch': 9.0}\n",
      "{'loss': 0.9844, 'grad_norm': 0.9298049211502075, 'learning_rate': 0.00040153846153846153, 'epoch': 9.2}\n",
      "{'loss': 0.9544, 'grad_norm': 1.6570651531219482, 'learning_rate': 0.0003876923076923077, 'epoch': 9.4}\n",
      "{'loss': 0.9045, 'grad_norm': 0.9034261107444763, 'learning_rate': 0.00037384615384615386, 'epoch': 9.6}\n",
      "{'loss': 0.9254, 'grad_norm': 0.8488160371780396, 'learning_rate': 0.00036, 'epoch': 9.8}\n",
      "{'loss': 0.9634, 'grad_norm': 2.051299810409546, 'learning_rate': 0.0003461538461538462, 'epoch': 10.0}\n",
      "{'loss': 0.7607, 'grad_norm': 0.9661478400230408, 'learning_rate': 0.0003323076923076923, 'epoch': 10.2}\n",
      "{'loss': 0.8288, 'grad_norm': 1.1078585386276245, 'learning_rate': 0.00031846153846153846, 'epoch': 10.4}\n",
      "{'loss': 0.7751, 'grad_norm': 1.1230874061584473, 'learning_rate': 0.0003046153846153846, 'epoch': 10.6}\n",
      "{'loss': 0.7456, 'grad_norm': 1.505463719367981, 'learning_rate': 0.0002907692307692308, 'epoch': 10.8}\n",
      "{'loss': 0.8114, 'grad_norm': 2.7807559967041016, 'learning_rate': 0.00027692307692307695, 'epoch': 11.0}\n",
      "{'loss': 0.7025, 'grad_norm': 1.7288343906402588, 'learning_rate': 0.00026307692307692306, 'epoch': 11.2}\n",
      "{'loss': 0.6515, 'grad_norm': 1.523063063621521, 'learning_rate': 0.0002492307692307692, 'epoch': 11.4}\n",
      "{'loss': 0.6063, 'grad_norm': 2.635930299758911, 'learning_rate': 0.00023538461538461538, 'epoch': 11.6}\n",
      "{'loss': 0.5762, 'grad_norm': 1.2561240196228027, 'learning_rate': 0.00022153846153846155, 'epoch': 11.8}\n",
      "{'loss': 0.6055, 'grad_norm': 2.2662651538848877, 'learning_rate': 0.0002076923076923077, 'epoch': 12.0}\n",
      "{'loss': 0.5664, 'grad_norm': 2.6604368686676025, 'learning_rate': 0.00019384615384615385, 'epoch': 12.2}\n",
      "{'loss': 0.5374, 'grad_norm': 1.7194256782531738, 'learning_rate': 0.00018, 'epoch': 12.4}\n",
      "{'loss': 0.4894, 'grad_norm': 1.674113154411316, 'learning_rate': 0.00016615384615384615, 'epoch': 12.6}\n",
      "{'loss': 0.4927, 'grad_norm': 1.2425388097763062, 'learning_rate': 0.0001523076923076923, 'epoch': 12.8}\n",
      "{'loss': 0.4237, 'grad_norm': 1.5863624811172485, 'learning_rate': 0.00013846153846153847, 'epoch': 13.0}\n",
      "{'loss': 0.4764, 'grad_norm': 1.0383046865463257, 'learning_rate': 0.0001246153846153846, 'epoch': 13.2}\n",
      "{'loss': 0.4325, 'grad_norm': 1.2956514358520508, 'learning_rate': 0.00011076923076923077, 'epoch': 13.4}\n",
      "{'loss': 0.4335, 'grad_norm': 2.072570323944092, 'learning_rate': 9.692307692307692e-05, 'epoch': 13.6}\n",
      "{'loss': 0.3967, 'grad_norm': 1.2402938604354858, 'learning_rate': 8.307692307692307e-05, 'epoch': 13.8}\n",
      "{'loss': 0.5043, 'grad_norm': 1.4775437116622925, 'learning_rate': 6.923076923076924e-05, 'epoch': 14.0}\n",
      "{'loss': 0.4222, 'grad_norm': 2.658693313598633, 'learning_rate': 5.538461538461539e-05, 'epoch': 14.2}\n",
      "{'loss': 0.3681, 'grad_norm': 2.4156272411346436, 'learning_rate': 4.153846153846154e-05, 'epoch': 14.4}\n",
      "{'loss': 0.399, 'grad_norm': 1.8364239931106567, 'learning_rate': 2.7692307692307694e-05, 'epoch': 14.6}\n",
      "{'loss': 0.3689, 'grad_norm': 1.4165239334106445, 'learning_rate': 1.3846153846153847e-05, 'epoch': 14.8}\n",
      "{'loss': 0.3995, 'grad_norm': 1.4662671089172363, 'learning_rate': 0.0, 'epoch': 15.0}\n",
      "{'train_runtime': 345.068, 'train_samples_per_second': 3.173, 'train_steps_per_second': 0.217, 'train_loss': 1.4254746309916178, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75, training_loss=1.4254746309916178, metrics={'train_runtime': 345.068, 'train_samples_per_second': 3.173, 'train_steps_per_second': 0.217, 'total_flos': 1.677999904653312e+16, 'train_loss': 1.4254746309916178, 'epoch': 15.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune model\n",
    "trainer=SFTTrainer(\n",
    "    model=ft_model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ft_train,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    packing=True,\n",
    "    args=TrainingArguments(\n",
    "        learning_rate=9e-4,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        per_device_train_batch_size=8,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=15,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=10,\n",
    "        output_dir=\"output\",\n",
    "        seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above finetuning run took about 5.5mins and used about 14.7GB of GRAM. I trained the model using my laptop's RTX4090 card with 16GB GRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 36.17 out of 62.53 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 135.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# save model weights\n",
    "ft_model.save_pretrained_merged(\"./Llama-3.2-1B-Instruct-ft\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test new finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.9.post4: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090 Laptop GPU. Max memory: 15.6 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:12<00:00, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6616161616161617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "ft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"./Llama-3.2-1B-Instruct-ft\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,\n",
    ")\n",
    "FastLanguageModel.for_inference(ft_model)\n",
    "\n",
    "ft_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=ft_model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "ft_llama_df, ft_llama_acc = rate_reviews(test, llama_generate, system_prompt, instruction, 'llama', ft_pipe)\n",
    "print(ft_llama_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tweaked several parameters (learning rate and num of epochs) in order to achieve the accuracy score above, which is quite close to the raw performance of GPT-4o-mini. I believe much more than be done in the future, once I am able to get more training data samples (which means more eating and reviewing on my side hahaha) as well as more compute to train larger models. With more datapoints and a usage of a larger model, i believe the fine-tuned model can achieve a higher performance compared to that of GPT-4o-mini. At the current performance of the finetuned model, I believe it is quite a feat considering only 600+ datapoints were fed to it during the training process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
